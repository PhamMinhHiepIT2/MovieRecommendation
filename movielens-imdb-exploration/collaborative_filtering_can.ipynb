{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "These notebook will compare the performance of _Neural Collaborative Filtering_ **[1]** and _Neural Graph Collaborative Filtering_ **[2]** papers on MovieLens dataset. We would like to see if there is a difference between non-graph based method and a graph-based method on collaborative filtering using MovieLens dataset. We will benefit from [this GitHub repository](https://github.com/talkingwallace/NGCF-pytorch/blob/master/GraphNCF/GCFmodel.py) **[3]** for the implementation of these two models.\n",
    "\n",
    "**Neural Collaborative Filtering: ** When it comes to model the key factor in collaborative filtering -- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering.\n",
    "\n",
    "**Neural Graph Collaborative Filtering: ** In this work, we propose to integrate the user-item interactions --- more specifically the bipartite graph structure --- into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. \n",
    "\n",
    "***\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "import time\n",
    "\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class RatingsDataset(Dataset):\n",
    "    \"\"\"Ratings Dataset\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with ratings.\n",
    "        \"\"\"\n",
    "        self.csv = pd.read_csv('data/ratings.csv')\n",
    "        \n",
    "        self.user_ids = list(self.csv.user_id-1)\n",
    "        self.movie_ids = list(self.csv.movie_id_ml-1)\n",
    "        self.ratings = list(self.csv.rating)\n",
    "        \n",
    "        self.userNums = np.max(self.user_ids)+1\n",
    "        self.movieNums = np.max(self.movie_ids)+1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user': self.user_ids[idx],\n",
    "            'movie': self.movie_ids[idx], \n",
    "            'rating': self.ratings[idx]\n",
    "        }\n",
    "    \n",
    "    def get_user_number(self):\n",
    "        return self.userNums\n",
    "    \n",
    "    def get_movie_number(self):\n",
    "        return self.movieNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.read_csv('data/ratings.csv')\n",
    "rt['user_id'] = rt['user_id'] - 1\n",
    "rt['movie_id_ml'] = rt['movie_id_ml'] - 1\n",
    "\n",
    "dataset = RatingsDataset()\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation - Neural Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(Module):\n",
    "\n",
    "    def __init__(self, userNum, itemNum, dim=64, first_layer=128):\n",
    "        super(NCF, self).__init__()\n",
    "        \n",
    "        self.uEmbd = nn.Embedding(userNum, dim)\n",
    "        self.iEmbd = nn.Embedding(itemNum, dim)\n",
    "        \n",
    "        self.mf_uEmbd = nn.Embedding(userNum, dim)\n",
    "        self.mf_iEmbd = nn.Embedding(itemNum, dim)\n",
    "        \n",
    "        self.mlp = nn.Sequential(nn.Linear(dim*2, first_layer),\n",
    "                                       nn.Dropout(0.25),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(first_layer, first_layer//2),\n",
    "                                       nn.Dropout(0.25),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(first_layer//2, first_layer//4),\n",
    "                                       nn.Dropout(0.25),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(first_layer//4, first_layer//4))\n",
    "        \n",
    "        self.neumf = nn.Linear(dim+first_layer//4, 1)\n",
    "        \n",
    "    def forward(self, userIdx,itemIdx):\n",
    "        uembd = self.uEmbd(userIdx)\n",
    "        iembd = self.iEmbd(itemIdx)\n",
    "        embd = torch.cat([uembd, iembd], dim=1)\n",
    "    \n",
    "        mlp = self.mlp(embd)\n",
    "        mf = self.uEmbd(userIdx)*self.iEmbd(itemIdx)\n",
    "        \n",
    "        prediction = self.neumf(torch.cat([mlp, mf], dim=1))\n",
    "        \n",
    "        return prediction.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation - Neural Graph Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(Module):\n",
    "\n",
    "    def __init__(self,inF,outF):\n",
    "\n",
    "        super(GNNLayer,self).__init__()\n",
    "        self.inF = inF\n",
    "        self.outF = outF\n",
    "        self.linear = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "        self.interActTransform = torch.nn.Linear(in_features=inF,out_features=outF)\n",
    "\n",
    "    def forward(self, laplacianMat,selfLoop,features):\n",
    "        L1 = laplacianMat + selfLoop\n",
    "        L2 = laplacianMat.cuda()\n",
    "        L1 = L1.cuda()\n",
    "        inter_feature = torch.mul(features,features)\n",
    "\n",
    "        inter_part1 = self.linear(torch.sparse.mm(L1,features))\n",
    "        inter_part2 = self.interActTransform(torch.sparse.mm(L2,inter_feature))\n",
    "\n",
    "        return inter_part1+inter_part2\n",
    "    \n",
    "class NGCF(Module):\n",
    "\n",
    "    def __init__(self,userNum,itemNum,rt,embedSize=100,layers=[100,80,50],useCuda=True):\n",
    "\n",
    "        super(NGCF,self).__init__()\n",
    "        self.useCuda = useCuda\n",
    "        self.userNum = userNum\n",
    "        self.itemNum = itemNum\n",
    "        self.uEmbd = nn.Embedding(userNum,embedSize)\n",
    "        self.iEmbd = nn.Embedding(itemNum,embedSize)\n",
    "        self.GNNlayers = torch.nn.ModuleList()\n",
    "        self.LaplacianMat = self.buildLaplacianMat(rt) # sparse format\n",
    "        self.selfLoop = self.getSparseEye(self.userNum+self.itemNum)\n",
    "\n",
    "        self.transForm1 = nn.Linear(in_features=layers[-1]*(len(layers))*2,out_features=64)\n",
    "        self.transForm2 = nn.Linear(in_features=64,out_features=32)\n",
    "        self.transForm3 = nn.Linear(in_features=32,out_features=1)\n",
    "\n",
    "        for From,To in zip(layers[:-1],layers[1:]):\n",
    "            self.GNNlayers.append(GNNLayer(From,To))\n",
    "\n",
    "    def getSparseEye(self,num):\n",
    "        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(0,num)]])\n",
    "        val = torch.FloatTensor([1]*num)\n",
    "        return torch.sparse.FloatTensor(i,val)\n",
    "\n",
    "    def buildLaplacianMat(self,rt):\n",
    "\n",
    "        rt_item = rt['movie_id_ml'] + self.userNum\n",
    "        uiMat = coo_matrix((rt['rating'], (rt['user_id'], rt['movie_id_ml'])))\n",
    "\n",
    "        uiMat_upperPart = coo_matrix((rt['rating'], (rt['user_id'], rt_item)))\n",
    "        uiMat = uiMat.transpose()\n",
    "        uiMat.resize((self.itemNum, self.userNum + self.itemNum))\n",
    "\n",
    "        A = sparse.vstack([uiMat_upperPart,uiMat])\n",
    "        selfLoop = sparse.eye(self.userNum+self.itemNum)\n",
    "        sumArr = (A>0).sum(axis=1)\n",
    "        diag = list(np.array(sumArr.flatten())[0])\n",
    "        diag = np.power(diag,-0.5)\n",
    "        D = sparse.diags(diag)\n",
    "        L = D * A * D\n",
    "        L = sparse.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        i = torch.LongTensor([row,col])\n",
    "        data = torch.FloatTensor(L.data)\n",
    "        SparseL = torch.sparse.FloatTensor(i,data)\n",
    "        return SparseL\n",
    "\n",
    "    def getFeatureMat(self):\n",
    "        uidx = torch.LongTensor([i for i in range(self.userNum)])\n",
    "        iidx = torch.LongTensor([i for i in range(self.itemNum)])\n",
    "        if self.useCuda == True:\n",
    "            uidx = uidx.cuda()\n",
    "            iidx = iidx.cuda()\n",
    "\n",
    "        userEmbd = self.uEmbd(uidx)\n",
    "        itemEmbd = self.iEmbd(iidx)\n",
    "        features = torch.cat([userEmbd,itemEmbd],dim=0)\n",
    "        return features\n",
    "\n",
    "    def forward(self,userIdx,itemIdx):\n",
    "\n",
    "        itemIdx = itemIdx + self.userNum\n",
    "        userIdx = list(userIdx.cpu().data)\n",
    "        itemIdx = list(itemIdx.cpu().data)\n",
    "        # gcf data propagation\n",
    "        features = self.getFeatureMat()\n",
    "        finalEmbd = features.clone()\n",
    "        for gnn in self.GNNlayers:\n",
    "            features = gnn(self.LaplacianMat,self.selfLoop,features)\n",
    "            features = nn.LeakyReLU()(features)\n",
    "            finalEmbd = torch.cat([finalEmbd,features.clone()],dim=1)\n",
    "\n",
    "        userEmbd = finalEmbd[userIdx]\n",
    "        itemEmbd = finalEmbd[itemIdx]\n",
    "        embd = torch.cat([userEmbd,itemEmbd],dim=1)\n",
    "\n",
    "        embd = nn.ReLU()(self.transForm1(embd))\n",
    "        embd = nn.ReLU()(self.transForm2(embd))\n",
    "        embd = self.transForm3(embd)\n",
    "        prediction = embd.flatten()\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, optim, loss):\n",
    "    model.train()\n",
    "    ls = 0.\n",
    "    \n",
    "    for id, batch in enumerate(loader):\n",
    "        optim.zero_grad()\n",
    "        prediction = model(batch['user'].cuda(0), batch['movie'].cuda(0))\n",
    "        loss_ = loss(batch['rating'].float().cuda(0), prediction)\n",
    "        loss_.backward()\n",
    "        optim.step()\n",
    "        ls += loss_.item()\n",
    "        \n",
    "    return ls / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(loader, model, loss):\n",
    "    model.eval()\n",
    "    ls = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for id, batch in enumerate(loader):\n",
    "            prediction = model(batch['user'].cuda(0), batch['movie'].cuda(0))\n",
    "            loss_ = loss(batch['rating'].float().cuda(0), prediction)\n",
    "            ls += loss_.item()\n",
    "            \n",
    "    return ls / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(trainLoader, valLoader, model, optim, loss, epoch, model_name, verbose=True):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val = np.inf\n",
    "\n",
    "    for i in range(epoch):\n",
    "        start = time.time()\n",
    "        TL = train(trainLoader, model, optim, loss)\n",
    "        VL = evaluate(valLoader, model, loss)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Epoch {} | Train Loss: {:.3f} - Val Loss: {:.3f} - in {:.3f} mins.\".format(i+1, TL, VL, (time.time()-start)/60))\n",
    "\n",
    "        if VL < best_val:\n",
    "            torch.save(model.state_dict(), model_name + '.pth.tar')\n",
    "            best_val = VL\n",
    "\n",
    "        train_losses.append(TL)\n",
    "        val_losses.append(VL)\n",
    "        \n",
    "    torch.save({\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'min_val_loss': min(val_losses)\n",
    "    }, model_name + '_loss.pth.tar')\n",
    "        \n",
    "    return torch.load(model_name + '_loss.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 64\n",
    "\n",
    "GRID_SEARCH = {\n",
    "    'batch_size': [128, 256, 512],\n",
    "    'first_layer': [64, 128, 256],\n",
    "    'learning_rate': [1e-3, 1e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 128 | First Layer Neuron: 64 | Learning Rate: 0.001 - Min. Val. Loss: 0.7356434101477648\n",
      "Batch Size: 128 | First Layer Neuron: 64 | Learning Rate: 0.01 - Min. Val. Loss: 0.8046537175392493\n",
      "Batch Size: 128 | First Layer Neuron: 128 | Learning Rate: 0.001 - Min. Val. Loss: 0.7446408038720106\n",
      "Batch Size: 128 | First Layer Neuron: 128 | Learning Rate: 0.01 - Min. Val. Loss: 0.790501879575925\n",
      "Batch Size: 128 | First Layer Neuron: 256 | Learning Rate: 0.001 - Min. Val. Loss: 0.7619099525304941\n",
      "Batch Size: 128 | First Layer Neuron: 256 | Learning Rate: 0.01 - Min. Val. Loss: 0.8142971514891355\n",
      "Batch Size: 256 | First Layer Neuron: 64 | Learning Rate: 0.001 - Min. Val. Loss: 0.7693888277579577\n",
      "Batch Size: 256 | First Layer Neuron: 64 | Learning Rate: 0.01 - Min. Val. Loss: 0.787121845361514\n",
      "Batch Size: 256 | First Layer Neuron: 128 | Learning Rate: 0.001 - Min. Val. Loss: 0.739997902741799\n",
      "Batch Size: 256 | First Layer Neuron: 128 | Learning Rate: 0.01 - Min. Val. Loss: 0.778801692601962\n",
      "Batch Size: 256 | First Layer Neuron: 256 | Learning Rate: 0.001 - Min. Val. Loss: 0.761417181063921\n",
      "Batch Size: 256 | First Layer Neuron: 256 | Learning Rate: 0.01 - Min. Val. Loss: 0.7787258808429425\n",
      "Batch Size: 512 | First Layer Neuron: 64 | Learning Rate: 0.001 - Min. Val. Loss: 0.7433245854500012\n",
      "Batch Size: 512 | First Layer Neuron: 64 | Learning Rate: 0.01 - Min. Val. Loss: 0.7835328028752253\n",
      "Batch Size: 512 | First Layer Neuron: 128 | Learning Rate: 0.001 - Min. Val. Loss: 0.7578102762882526\n",
      "Batch Size: 512 | First Layer Neuron: 128 | Learning Rate: 0.01 - Min. Val. Loss: 0.7696724579884455\n",
      "Batch Size: 512 | First Layer Neuron: 256 | Learning Rate: 0.001 - Min. Val. Loss: 0.7611865676366366\n",
      "Batch Size: 512 | First Layer Neuron: 256 | Learning Rate: 0.01 - Min. Val. Loss: 0.7690369333976355\n"
     ]
    }
   ],
   "source": [
    "for bs in GRID_SEARCH['batch_size']:\n",
    "    for layer in GRID_SEARCH['first_layer']:\n",
    "        for lr in GRID_SEARCH['learning_rate']:\n",
    "            \n",
    "            trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=4, drop_last=True)\n",
    "            valLoader = torch.utils.data.DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=4, drop_last=True)\n",
    "            \n",
    "            model = NCF(dataset.get_user_number(), dataset.get_movie_number(), \n",
    "                        dim=EMBEDDING_DIM, first_layer=layer).cuda(0)\n",
    "            \n",
    "            optim = Adam(model.parameters(), lr=lr)\n",
    "            loss = nn.L1Loss()\n",
    "            epoch = 20\n",
    "            \n",
    "            ncf_out = trainer(trainLoader, valLoader, model, optim, loss, epoch, 'ncf_model', False)\n",
    "            \n",
    "            print(\"Batch Size: {} | First Layer Neuron: {} | Learning Rate: {} - Min. Val. Loss: {}\".format(bs, \n",
    "                                                                                                            layer, \n",
    "                                                                                                            lr, \n",
    "                                                                                                            ncf_out['min_val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGCF Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 64\n",
    "\n",
    "GRID_SEARCH = {\n",
    "    'batch_size': [256, 512, 1024],\n",
    "    'layers': [[64,64], [64,64,64], [64,64,64,64]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 256 | First Layer Neuron: [64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7478925876128368\n",
      "Batch Size: 256 | First Layer Neuron: [64, 64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.723776468863854\n",
      "Batch Size: 256 | First Layer Neuron: [64, 64, 64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7210972034014188\n",
      "Batch Size: 512 | First Layer Neuron: [64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.746336606832651\n",
      "Batch Size: 512 | First Layer Neuron: [64, 64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7237180119905716\n",
      "Batch Size: 512 | First Layer Neuron: [64, 64, 64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7286107692963038\n",
      "Batch Size: 1024 | First Layer Neuron: [64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7496198196160165\n",
      "Batch Size: 1024 | First Layer Neuron: [64, 64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7319987290783933\n",
      "Batch Size: 1024 | First Layer Neuron: [64, 64, 64, 64] | Learning Rate: 0.001 - Min. Val. Loss: 0.7402098335717854\n"
     ]
    }
   ],
   "source": [
    "for bs in GRID_SEARCH['batch_size']:\n",
    "    for layer in GRID_SEARCH['layers']:     \n",
    "        \n",
    "        trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=4, drop_last=True)\n",
    "        valLoader = torch.utils.data.DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "        model = NGCF(dataset.get_user_number(), dataset.get_movie_number(), rt, EMBEDDING_DIM, layers=layer).cuda(0)\n",
    "        optim = Adam(model.parameters(), lr=1e-3)\n",
    "        loss = nn.L1Loss()\n",
    "        epoch = 20\n",
    "\n",
    "        ncf_out = trainer(trainLoader, valLoader, model, optim, loss, epoch, 'ngcf_model', False)\n",
    "\n",
    "        print(\"Batch Size: {} | First Layer Neuron: {} | Learning Rate: {} - Min. Val. Loss: {}\".format(bs, \n",
    "                                                                                                        layer, \n",
    "                                                                                                        lr, \n",
    "                                                                                                        ncf_out['min_val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Neural Collaborative Filtering Model')\n",
    "plt.plot(ncf_out['train_losses'], label='Training')\n",
    "plt.plot(ncf_out['val_losses'], label='Validation')\n",
    "_ = plt.ylabel('L1 Loss')\n",
    "_ = plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## References\n",
    "\n",
    "[1] _He, Xiangnan, et al. \"Neural collaborative filtering.\" Proceedings of the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee, 2017._\n",
    "\n",
    "[2] _Wang, Xiang, et al. \"Neural Graph Collaborative Filtering.\" arXiv preprint arXiv:1905.08108 (2019)._\n",
    "\n",
    "[3] _https://github.com/talkingwallace/NGCF-pytorch_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
